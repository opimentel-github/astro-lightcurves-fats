{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../flaming-choripan') # or just install the module\n",
    "sys.path.append('../../astro-lightcurves-handler') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "found filedirs: (../../surveys-save)\n",
      "(0) - ../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe°method=linear.splcds - 27.269[mbs]\n",
      "(1) - ../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe.splcds - 4.557[mbs]\n",
      "(2) - ../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe°method=curvefit.splcds - 28.666[mbs]\n",
      "(3) - ../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe°method=bspline.splcds - 27.244[mbs]\n",
      "(4) - ../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe°method=mcmc.splcds - 28.559[mbs]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "filedirs after searching with filters: (../../surveys-save)\n",
      "(0) - ../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe°method=linear.splcds - 27.269[mbs]\n",
      "(1) - ../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe.splcds - 4.557[mbs]\n",
      "(2) - ../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe°method=curvefit.splcds - 28.666[mbs]\n",
      "(3) - ../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe°method=bspline.splcds - 27.244[mbs]\n",
      "(4) - ../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe°method=mcmc.splcds - 28.559[mbs]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "from flamingchoripan.files import search_for_filedirs\n",
    "from lchandler import C_\n",
    "\n",
    "root_folder = '../../surveys-save'\n",
    "filedirs = search_for_filedirs(root_folder, fext=C_.EXT_SPLIT_LIGHTCURVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m> loading: ../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe.splcds\u001b[0m\n",
      "dict_keys(['data', 'survey', 'description', 'band_names', 'class_names', 'obs_is_flux'])\n",
      "dict_keys(['days', 'obs', 'obse', 'y', 'synthetic'])\n",
      "LCDataset:\n",
      "[outliers - samples 10]\n",
      "(*) obs_samples: 541 - min_len: 14 - max_dur: 408.0[days] - dur(p50): 133.8[days] - cadence(p50): 1.0[days]\n",
      "(g) obs_samples: 260 - min_len: 6 - max_dur: 408.0[days] - dur(p50): 133.8[days] - cadence(p50): 3.0[days]\n",
      "(r) obs_samples: 281 - min_len: 8 - max_dur: 376.0[days] - dur(p50): 128.7[days] - cadence(p50): 3.0[days]\n",
      "   |█▌      | SLSN - 2/10 (20.00%)\n",
      "   |▊       | SNIa - 1/10 (10.00%)\n",
      "   |█▌      | SNIbc - 2/10 (20.00%)\n",
      "   |████    | allSNII - 5/10 (50.00%)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[faint - samples 48]\n",
      "(*) obs_samples: 1,107 - min_len: 7 - max_dur: 298.1[days] - dur(p50): 40.5[days] - cadence(p50): 1.0[days]\n",
      "(g) obs_samples: 450 - min_len: 0 - max_dur: 221.7[days] - dur(p50): 28.0[days] - cadence(p50): 2.9[days]\n",
      "(r) obs_samples: 657 - min_len: 4 - max_dur: 298.1[days] - dur(p50): 38.9[days] - cadence(p50): 2.9[days]\n",
      "   |█▏      | SLSN - 7/48 (14.58%)\n",
      "   |███▊    | SNIa - 23/48 (47.92%)\n",
      "   |▌       | SNIbc - 3/48 (6.25%)\n",
      "   |██▌     | allSNII - 15/48 (31.25%)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[raw - samples 1,940]\n",
      "(*) obs_samples: 53,326 - min_len: 6 - max_dur: 538.8[days] - dur(p50): 53.0[days] - cadence(p50): 1.0[days]\n",
      "(g) obs_samples: 23,566 - min_len: 0 - max_dur: 538.7[days] - dur(p50): 39.0[days] - cadence(p50): 3.0[days]\n",
      "(r) obs_samples: 29,760 - min_len: 0 - max_dur: 538.7[days] - dur(p50): 51.0[days] - cadence(p50): 3.0[days]\n",
      "   |        | SLSN - 22/1,940 (1.13%)\n",
      "   |██████  | SNIa - 1,477/1,940 (76.13%)\n",
      "   |▍       | SNIbc - 95/1,940 (4.90%)\n",
      "   |█▍      | allSNII - 346/1,940 (17.84%)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[train - samples 1,239]\n",
      "(*) obs_samples: 34,283 - min_len: 6 - max_dur: 444.7[days] - dur(p50): 52.9[days] - cadence(p50): 1.0[days]\n",
      "(g) obs_samples: 15,098 - min_len: 0 - max_dur: 443.9[days] - dur(p50): 39.0[days] - cadence(p50): 3.0[days]\n",
      "(r) obs_samples: 19,185 - min_len: 0 - max_dur: 443.9[days] - dur(p50): 50.9[days] - cadence(p50): 3.0[days]\n",
      "   |        | SLSN - 14/1,239 (1.13%)\n",
      "   |██████  | SNIa - 944/1,239 (76.19%)\n",
      "   |▍       | SNIbc - 60/1,239 (4.84%)\n",
      "   |█▍      | allSNII - 221/1,239 (17.84%)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[val - samples 309]\n",
      "(*) obs_samples: 8,532 - min_len: 8 - max_dur: 538.8[days] - dur(p50): 53.9[days] - cadence(p50): 1.7[days]\n",
      "(g) obs_samples: 3,847 - min_len: 0 - max_dur: 538.7[days] - dur(p50): 39.4[days] - cadence(p50): 3.0[days]\n",
      "(r) obs_samples: 4,685 - min_len: 2 - max_dur: 538.7[days] - dur(p50): 52.0[days] - cadence(p50): 3.0[days]\n",
      "   |        | SLSN - 3/309 (0.97%)\n",
      "   |██████  | SNIa - 236/309 (76.38%)\n",
      "   |▍       | SNIbc - 15/309 (4.85%)\n",
      "   |█▍      | allSNII - 55/309 (17.80%)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[test - samples 391]\n",
      "(*) obs_samples: 10,444 - min_len: 6 - max_dur: 283.1[days] - dur(p50): 53.9[days] - cadence(p50): 1.0[days]\n",
      "(g) obs_samples: 4,595 - min_len: 0 - max_dur: 232.2[days] - dur(p50): 39.9[days] - cadence(p50): 3.0[days]\n",
      "(r) obs_samples: 5,849 - min_len: 0 - max_dur: 283.1[days] - dur(p50): 51.9[days] - cadence(p50): 3.0[days]\n",
      "   |        | SLSN - 5/391 (1.28%)\n",
      "   |██████  | SNIa - 296/391 (75.70%)\n",
      "   |▍       | SNIbc - 20/391 (5.12%)\n",
      "   |█▍      | allSNII - 70/391 (17.90%)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from flamingchoripan.files import load_pickle, save_pickle\n",
    "from flamingchoripan.files import get_dict_from_filedir\n",
    "from lchandler import C_\n",
    "\n",
    "def load_lcdataset(filename):\n",
    "    assert filename.split('.')[-1]==C_.EXT_SPLIT_LIGHTCURVE\n",
    "    return load_pickle(filename)\n",
    "\n",
    "filedir = f'../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe.splcds'\n",
    "\n",
    "filedict = get_dict_from_filedir(filedir)\n",
    "root_folder = filedict['*rootdir*']\n",
    "cfilename = filedict['*cfilename*']\n",
    "survey = filedict['survey']\n",
    "lcdataset = load_lcdataset(filedir)\n",
    "print(lcdataset['raw'].keys())\n",
    "print(lcdataset['raw'].get_random_lcobj(False).keys())\n",
    "print(lcdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\u001b[34m> loading: ../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe°method=curvefit.splcds\u001b[0m\n",
      "  0%|          | 0/3 [00:00, ?it/s, training id: 0]"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/tesla/oscar/tesis/astro-lightcurves-fats/save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe°method=curvefit/features/train.ftres.x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0454dc8b865b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;34m'remove_real_samples'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mremove_real\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         }\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mclassifier_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fitted_classifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlcdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_lcset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_rootdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mtrain_lcset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{train_lcset_name}{\"-only\" if remove_real else \"\"}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mrf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_lcset_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_classifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlcdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_lcset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_rootdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oscar/tesis/astro-lightcurves-fats/lcfats/classifiers.py\u001b[0m in \u001b[0;36mget_fitted_classifiers\u001b[0;34m(lcdataset, train_lcset_name, load_rootdir, max_model_ids, remove_real_samples)\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mbrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBalancedRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbrf_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;31m#brf = RandomForestClassifier(**brf_kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mx_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{load_rootdir}/{train_lcset_name}.ftres'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mremove_real_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oscar/tesis/astro-lightcurves-fats/lcfats/files.py\u001b[0m in \u001b[0;36mload_features\u001b[0;34m(load_filedir)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_filedir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{load_filedir}.x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# parquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0my_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{load_filedir}.y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# parquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lchandler/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     return impl.read(\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/envs/lchandler/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filesystem\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         )\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lchandler/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# fsspec resources can also point to directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mhandles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mpath_or_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lchandler/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/tesla/oscar/tesis/astro-lightcurves-fats/save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe°method=curvefit/features/train.ftres.x'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from flamingchoripan.files import load_pickle, save_pickle\n",
    "from flamingchoripan.files import get_dict_from_filedir\n",
    "from lchandler import C_\n",
    "from lcfats.classifiers import get_fitted_classifiers, evaluate_classifiers\n",
    "from flamingchoripan.cuteplots.cm_plots import plot_custom_confusion_matrix\n",
    "from flamingchoripan.datascience.statistics import XError\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_model_ids = 3\n",
    "test_lcset_name = 'val' # val test\n",
    "methods = ['curvefit', 'mcmc', 'linear', 'bspline']\n",
    "for method in methods:\n",
    "    new_cfilename = f'{cfilename}°method={method}'\n",
    "    filedir = f'{root_folder}/{new_cfilename}.{C_.EXT_SPLIT_LIGHTCURVE}'\n",
    "    lcdataset = load_lcdataset(filedir)\n",
    "    #print(lcdataset)\n",
    "    #assert 0\n",
    "    rf_results = {}\n",
    "    train_configs = [\n",
    "        ('train', False),\n",
    "        (f'train.{method}', False),\n",
    "        (f'train.{method}', True),\n",
    "    ]\n",
    "    for (train_lcset_name,remove_real) in train_configs:\n",
    "        load_rootdir = f'../save/{survey}/{new_cfilename}/features'\n",
    "        fit_kwargs = {\n",
    "            'max_model_ids':max_model_ids,\n",
    "            'remove_real_samples':remove_real,\n",
    "        }\n",
    "        classifier_dict, model_ids = get_fitted_classifiers(lcdataset, train_lcset_name, load_rootdir, **fit_kwargs)\n",
    "        train_lcset_name = f'{train_lcset_name}{\"-only\" if remove_real else \"\"}'\n",
    "        rf_results[train_lcset_name] = evaluate_classifiers(lcdataset, test_lcset_name, classifier_dict, model_ids, load_rootdir)\n",
    "        \n",
    "        ### plot cms\n",
    "        d = rf_results[train_lcset_name]\n",
    "        lcset_name = d[model_ids[0]]['lcset_name']\n",
    "        class_names = d[model_ids[0]]['class_names']\n",
    "        cms = [d[id]['cm'][None] for id in model_ids]\n",
    "        f1score_xe = XError([d[id]['f1score'] for id in model_ids])\n",
    "        title = f'train set: {train_lcset_name} - evaluation set: {lcset_name}\\n'\n",
    "        title += f'b-f1score: {f1score_xe}'\n",
    "        cm_kwargs = {\n",
    "            'title':title,\n",
    "            'figsize':(6,5),\n",
    "            'new_order_classes':['SNIa', 'SNIbc', 'allSNII', 'SLSN'],\n",
    "        }\n",
    "        fig, ax = plot_custom_confusion_matrix(np.concatenate(cms, axis=0), class_names, **cm_kwargs)\n",
    "        plt.show()\n",
    "        \n",
    "        ### print rank\n",
    "        #print(classifier_dict[0]['rank'])\n",
    "        \n",
    "    save_filedir = f'../save/{survey}/{new_cfilename}/rf.res'\n",
    "    save_pickle(save_filedir, rf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from flamingchoripan.files import load_pickle, save_pickle\n",
    "from flamingchoripan.datascience.statistics import XError\n",
    "from flamingchoripan.latex.latex_tables import LatexTable\n",
    "import pandas as pd\n",
    "\n",
    "methods = ['linear', 'bspline', 'curvefit', 'uniformprior', 'mcmc']\n",
    "info_dict = {}\n",
    "for km,method in enumerate(methods):\n",
    "    new_cfilename = f'{cfilename}°method={method}'\n",
    "    load_filedir = f'../save/{survey}/{new_cfilename}/rf.res'\n",
    "    rf_results = load_pickle(load_filedir)\n",
    "    model_ids = list(rf_results['train+val'].keys())\n",
    "    d = {\n",
    "        'b-accu[%] | real':XError([rf_results[f'train+val'][id]['accu']*100 for id in model_ids]),\n",
    "        'b-f1score | real':XError([rf_results[f'train+val'][id]['f1score'] for id in model_ids]),\n",
    "        'b-accu[%] | synth':XError([rf_results[f'train+val.{method}-only'][id]['accu']*100 for id in model_ids]),\n",
    "        'b-f1score | synth':XError([rf_results[f'train+val.{method}-only'][id]['f1score'] for id in model_ids]),\n",
    "        'b-accu[%] | real+synth':XError([rf_results[f'train+val.{method}'][id]['accu']*100 for id in model_ids]),\n",
    "        'b-f1score | real+synth':XError([rf_results[f'train+val.{method}'][id]['f1score'] for id in model_ids]),\n",
    "    }\n",
    "    info_dict[f'method={method}'] = d\n",
    "    \n",
    "info_df = pd.DataFrame.from_dict(info_dict, orient='index').reindex(list(info_dict.keys()))\n",
    "info_df = info_df.sort_values(by=['b-f1score | real+synth'])\n",
    "info_df['b-accu[%] | real'] = [v if k==0 else XError(None) for k,v in enumerate(info_df['b-accu[%] | real'].values)]\n",
    "info_df['b-f1score | real'] = [v if k==0 else XError(None) for k,v in enumerate(info_df['b-f1score | real'].values)]\n",
    "\n",
    "latex_kwargs = {\n",
    "    'caption':'$x_j$',\n",
    "    'label':'???',\n",
    "    'bold_criteriums':'max',\n",
    "    'custom_tabular_align':'l|cc|cc|cc',\n",
    "}\n",
    "latex_table = LatexTable(info_df, **latex_kwargs)\n",
    "print(latex_table)\n",
    "info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from flamingchoripan.files import load_pickle, save_pickle\n",
    "from flamingchoripan.datascience.statistics import XError\n",
    "from flamingchoripan.latex.latex_tables import LatexTable\n",
    "import pandas as pd\n",
    "\n",
    "methods = ['linear', 'bspline', 'curvefit']#, 'uniformprior']\n",
    "info_dict = {}\n",
    "for km,method in enumerate(methods):\n",
    "    new_cfilename = f'{cfilename}°method={method}'\n",
    "    load_filedir = f'../save/{survey}/{new_cfilename}/rf.res'\n",
    "    rf_results = load_pickle(load_filedir)\n",
    "    model_ids = list(rf_results['train+val'].keys())\n",
    "    rank = rf_results['train+val'][model_ids[0]]['rank']\n",
    "    features = rf_results['train+val'][model_ids[0]]['features']\n",
    "    print(len(features), features)\n",
    "    rank.print_n = 20\n",
    "    rank.values = [v*100 for v in rank.values]\n",
    "    rank.name = 'RF-ranking[%]'\n",
    "    df = rank.get_df()\n",
    "    df.index = [f'FATS-features={i.replace(\"_\", \"-\")}' for i in list(df.index)]\n",
    "    info_dict[method] = df\n",
    "info_df = info_dict['curvefit']\n",
    "    \n",
    "latex_kwargs = {\n",
    "    'caption':'$x_j$',\n",
    "    'label':'???',\n",
    "}\n",
    "latex_table = LatexTable(info_df, **latex_kwargs)\n",
    "print(latex_table)\n",
    "info_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
